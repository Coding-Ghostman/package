"use strict";
/**
 * Generative AI Service Inference API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings.

Use the Generative AI service inference API to access your custom model endpoints, or to try the out-of-the-box models to [chat](#/en/generative-ai-inference/latest/ChatResult/Chat), [generate text](#/en/generative-ai-inference/latest/GenerateTextResult/GenerateText), [summarize](#/en/generative-ai-inference/latest/SummarizeTextResult/SummarizeText), and [create text embeddings](#/en/generative-ai-inference/latest/EmbedTextResult/EmbedText).

To use a Generative AI custom model for inference, you must first create an endpoint for that model. Use the [Generative AI service management API](/#/en/generative-ai/latest/) to [create a custom model](#/en/generative-ai/latest/Model/) by fine-tuning an out-of-the-box model, or a previous version of a custom model, using your own data. Fine-tune the custom model on a  [fine-tuning dedicated AI cluster](#/en/generative-ai/latest/DedicatedAiCluster/). Then, create a [hosting dedicated AI cluster](#/en/generative-ai/latest/DedicatedAiCluster/) with an [endpoint](#/en/generative-ai/latest/Endpoint/) to host your custom model. For resource management in the Generative AI service, use the [Generative AI service management API](/#/en/generative-ai/latest/).

To learn more about the service, see the [Generative AI documentation](/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 *
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2024, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.UserMessage = exports.TextContent = exports.SystemMessage = exports.OnDemandServingMode = exports.LlamaLlmInferenceResponse = exports.LlamaLlmInferenceRequest = exports.GenericChatResponse = exports.GenericChatRequest = exports.DedicatedServingMode = exports.CohereUserMessage = exports.CohereToolMessage = exports.CohereSystemMessage = exports.CohereLlmInferenceResponse = exports.CohereLlmInferenceRequest = exports.CohereChatResponse = exports.CohereChatRequest = exports.CohereChatBotMessage = exports.AssistantMessage = exports.TokenLikelihood = exports.SummarizeTextResult = exports.SummarizeTextDetails = exports.ServingMode = exports.SearchQuery = exports.Message = exports.Logprobs = exports.LlmInferenceResponse = exports.LlmInferenceRequest = exports.GeneratedText = exports.GenerateTextResult = exports.GenerateTextDetails = exports.EmbedTextResult = exports.EmbedTextDetails = exports.CohereToolResult = exports.CohereToolCall = exports.CohereTool = exports.CohereParameterDefinition = exports.CohereMessage = exports.Citation = exports.Choice = exports.ChatResult = exports.ChatDetails = exports.ChatContent = exports.ChatChoice = exports.BaseChatResponse = exports.BaseChatRequest = void 0;
const BaseChatRequest = __importStar(require("./base-chat-request"));
exports.BaseChatRequest = BaseChatRequest.BaseChatRequest;
const BaseChatResponse = __importStar(require("./base-chat-response"));
exports.BaseChatResponse = BaseChatResponse.BaseChatResponse;
const ChatChoice = __importStar(require("./chat-choice"));
exports.ChatChoice = ChatChoice.ChatChoice;
const ChatContent = __importStar(require("./chat-content"));
exports.ChatContent = ChatContent.ChatContent;
const ChatDetails = __importStar(require("./chat-details"));
exports.ChatDetails = ChatDetails.ChatDetails;
const ChatResult = __importStar(require("./chat-result"));
exports.ChatResult = ChatResult.ChatResult;
const Choice = __importStar(require("./choice"));
exports.Choice = Choice.Choice;
const Citation = __importStar(require("./citation"));
exports.Citation = Citation.Citation;
const CohereMessage = __importStar(require("./cohere-message"));
exports.CohereMessage = CohereMessage.CohereMessage;
const CohereParameterDefinition = __importStar(require("./cohere-parameter-definition"));
exports.CohereParameterDefinition = CohereParameterDefinition.CohereParameterDefinition;
const CohereTool = __importStar(require("./cohere-tool"));
exports.CohereTool = CohereTool.CohereTool;
const CohereToolCall = __importStar(require("./cohere-tool-call"));
exports.CohereToolCall = CohereToolCall.CohereToolCall;
const CohereToolResult = __importStar(require("./cohere-tool-result"));
exports.CohereToolResult = CohereToolResult.CohereToolResult;
const EmbedTextDetails = __importStar(require("./embed-text-details"));
exports.EmbedTextDetails = EmbedTextDetails.EmbedTextDetails;
const EmbedTextResult = __importStar(require("./embed-text-result"));
exports.EmbedTextResult = EmbedTextResult.EmbedTextResult;
const GenerateTextDetails = __importStar(require("./generate-text-details"));
exports.GenerateTextDetails = GenerateTextDetails.GenerateTextDetails;
const GenerateTextResult = __importStar(require("./generate-text-result"));
exports.GenerateTextResult = GenerateTextResult.GenerateTextResult;
const GeneratedText = __importStar(require("./generated-text"));
exports.GeneratedText = GeneratedText.GeneratedText;
const LlmInferenceRequest = __importStar(require("./llm-inference-request"));
exports.LlmInferenceRequest = LlmInferenceRequest.LlmInferenceRequest;
const LlmInferenceResponse = __importStar(require("./llm-inference-response"));
exports.LlmInferenceResponse = LlmInferenceResponse.LlmInferenceResponse;
const Logprobs = __importStar(require("./logprobs"));
exports.Logprobs = Logprobs.Logprobs;
const Message = __importStar(require("./message"));
exports.Message = Message.Message;
const SearchQuery = __importStar(require("./search-query"));
exports.SearchQuery = SearchQuery.SearchQuery;
const ServingMode = __importStar(require("./serving-mode"));
exports.ServingMode = ServingMode.ServingMode;
const SummarizeTextDetails = __importStar(require("./summarize-text-details"));
exports.SummarizeTextDetails = SummarizeTextDetails.SummarizeTextDetails;
const SummarizeTextResult = __importStar(require("./summarize-text-result"));
exports.SummarizeTextResult = SummarizeTextResult.SummarizeTextResult;
const TokenLikelihood = __importStar(require("./token-likelihood"));
exports.TokenLikelihood = TokenLikelihood.TokenLikelihood;
const AssistantMessage = __importStar(require("./assistant-message"));
exports.AssistantMessage = AssistantMessage.AssistantMessage;
const CohereChatBotMessage = __importStar(require("./cohere-chat-bot-message"));
exports.CohereChatBotMessage = CohereChatBotMessage.CohereChatBotMessage;
const CohereChatRequest = __importStar(require("./cohere-chat-request"));
exports.CohereChatRequest = CohereChatRequest.CohereChatRequest;
const CohereChatResponse = __importStar(require("./cohere-chat-response"));
exports.CohereChatResponse = CohereChatResponse.CohereChatResponse;
const CohereLlmInferenceRequest = __importStar(require("./cohere-llm-inference-request"));
exports.CohereLlmInferenceRequest = CohereLlmInferenceRequest.CohereLlmInferenceRequest;
const CohereLlmInferenceResponse = __importStar(require("./cohere-llm-inference-response"));
exports.CohereLlmInferenceResponse = CohereLlmInferenceResponse.CohereLlmInferenceResponse;
const CohereSystemMessage = __importStar(require("./cohere-system-message"));
exports.CohereSystemMessage = CohereSystemMessage.CohereSystemMessage;
const CohereToolMessage = __importStar(require("./cohere-tool-message"));
exports.CohereToolMessage = CohereToolMessage.CohereToolMessage;
const CohereUserMessage = __importStar(require("./cohere-user-message"));
exports.CohereUserMessage = CohereUserMessage.CohereUserMessage;
const DedicatedServingMode = __importStar(require("./dedicated-serving-mode"));
exports.DedicatedServingMode = DedicatedServingMode.DedicatedServingMode;
const GenericChatRequest = __importStar(require("./generic-chat-request"));
exports.GenericChatRequest = GenericChatRequest.GenericChatRequest;
const GenericChatResponse = __importStar(require("./generic-chat-response"));
exports.GenericChatResponse = GenericChatResponse.GenericChatResponse;
const LlamaLlmInferenceRequest = __importStar(require("./llama-llm-inference-request"));
exports.LlamaLlmInferenceRequest = LlamaLlmInferenceRequest.LlamaLlmInferenceRequest;
const LlamaLlmInferenceResponse = __importStar(require("./llama-llm-inference-response"));
exports.LlamaLlmInferenceResponse = LlamaLlmInferenceResponse.LlamaLlmInferenceResponse;
const OnDemandServingMode = __importStar(require("./on-demand-serving-mode"));
exports.OnDemandServingMode = OnDemandServingMode.OnDemandServingMode;
const SystemMessage = __importStar(require("./system-message"));
exports.SystemMessage = SystemMessage.SystemMessage;
const TextContent = __importStar(require("./text-content"));
exports.TextContent = TextContent.TextContent;
const UserMessage = __importStar(require("./user-message"));
exports.UserMessage = UserMessage.UserMessage;
//# sourceMappingURL=index.js.map